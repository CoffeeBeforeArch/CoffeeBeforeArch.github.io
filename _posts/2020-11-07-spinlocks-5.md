---
layout: default
title: Spinlocks - Part 5
---

# Spinlocks - Part 5

In the [last blog post](https://coffeebeforearch.github.io/2020/11/07/spinlocks-5.html), we used the passive backoff optimization to reduce the power consumption of our spinlock. However, we don't always want our threads pause for constant amount of time.

In this blog post, we'll look at two spinlocks that use a non-constant form of backoff (exponential and random).

### Link to the source code

- [Source Code: ](https://github.com/CoffeeBeforeArch/spinlocks)
- [My YouTube Channel: ](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account: ](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com

## Our Benchmark

We will evaluate our spinlock implementations using [Google Benchmark](https://github.com/google/benchmark). The structure of the benchmark can be found below:

```cpp
 // Small Benchmark
 static void bench(benchmark::State &s) {
   // Sweep over a range of threads
   auto num_threads = s.range(0);
 
   // Value we will increment
   std::int64_t val = 0;
 
   // Allocate a vector of threads
   std::vector<std::thread> threads;
   threads.reserve(num_threads);
 
   Spinlock sl;
 
   // Timing loop
   for (auto _ : s) {
     for (auto i = 0u; i < num_threads; i++) {
       threads.emplace_back([&] { inc(sl, val); });
     }
     // Join threads
     for (auto &thread : threads) thread.join();
     threads.clear();
   }
 }
 BENCHMARK(bench)
     ->RangeMultiplier(2)
     ->Range(1, std::thread::hardware_concurrency())
     ->UseRealTime()
     ->Unit(benchmark::kMillisecond);
```

We'll be evaluating our benchmark for a power-of-two number of threads (1, 2, 4, and 8 on my machine), where each thread runs a function called `inc`. This function can be found below:

```cpp
 // Increment val once each time the lock is acquired
 void inc(Spinlock &s, std::int64_t &val) {
   for (int i = 0; i < 100000; i++) {
     s.lock();
     val++;
     s.unlock();
   }
 }
```

For 100k iterations, our threads try and lock our spinlock, increment a shared value, then release the lock. This gives us a heavy contention scenario in which to test our spinlock.

## A Spinlock with Non-Constant Backoff

We don't always want to pause for a constant amount of time. For example, if one of our threads is holding the lock for longer than expected, we might want to increase the time between reads of the spinlock state.

Let's take a look at two non-constant backoff implementations. In our first implementation, we'll look at an optimization called exponential backoff where the number of pause iterations increases exponentially the longer we wait for the lock. In our second, we'll look at a random backoff optimization where the number of pause iterations comes from a random number generator.

### Exponential Backoff

The core idea behind exponential backoff is that threads that continuously find that the spinlock is still not available should wait longer between each read of the spinlock state. Here's how our updated spinlock `lock` method looks:

```cpp
  // Locking mechanism
  void lock() {
    // Start backoff at MIN_BACKOFF iterations
    int backoff_iters = MIN_BACKOFF;

    // Keep trying
    while (1) {
      // Try and grab the lock
      if (!locked.exchange(true)) return;

      // Pause for an exponentially increasing number of iterations
      do {
        for (int i = 0; i < backoff_iters; i++) _mm_pause();

        // Get the backoff iterations for next time
        backoff_iters = std::min(backoff_iters << 1, MAX_BACKOFF);

        // Check to see if the lock is free
      } while (locked.load());
    }
  }
```

We start our backoff iterations (`backoff_iters`) at some minimum value (this is a tunable). If a thread fails to get the lock with the atomic exchange, it falls into our spinning locally loop where we pause for `backoff_iters` number of iterations. We then exponentially increase the number of backoff iterations for the next trip in the loop, read the spinlock state, and either go back to the top of the loop, or try for the lock again.

One thing to notice is that we cap the number of backoff iterations to `MAX_BACKOFF`. This is generally a good idea, because exponential numbers grow quickly (who would have thought!). If we did not bound this to a maximum, our number of backoff iterations could grow so quickly that all our threads end up waiting un-necessarily long in the delay loop even after the lock as become free.

### Random Backoff

## Final Thoughts

Thanks for reading,

--Nick

### Link to the source code

- [Source Code: ](https://github.com/CoffeeBeforeArch/spinlocks)
- [My YouTube Channel: ](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account: ](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com

