---
layout: default
title: Multithreading - Not a Panacea
---

# GEMM (Matrix Multiplication)

Matrix multiplication is an incredibly common operation across numerous domains. It is also known as being "embarrissingly parallel". As such, one common optimization is parallelization across threads on a multi-core CPU or GPU. However, parallelization is not a panacea. Poorly parallelized code may provide minimal speedups (if any). In this blog post, we'll be comparing a few different implementations of matrix multiplication.

## Links

- [My YouTube Channel](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com

## Matrix Multiplication - Baseline

## Matrix Multiplication - Aligned Memory

## Matrix Multiplication - Parallel

## Matrix Multiplication - Blocking

## Concluding Remarks

As always, feel free to contact me with questions.

Cheers,

--Nick

## Links

- [My YouTube Channel](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com
