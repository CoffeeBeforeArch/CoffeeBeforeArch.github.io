---
layout: default
title: Spinlocks - Part 6
---

# Spinlocks - Part 6

In the [last blog post](https://coffeebeforearch.github.io/2020/11/07/spinlocks-6.html), we looked at non-constant forms of backoff that further improved the end-to-end execution time of our benchmarks. However, optimizations that help with throughput/performance may hurt other metrics like fairness.

In this blog post, we'll look at a spinlock implementation optimized for fairness called a ticket spinlock.

### Link to the source code

- [Source Code: ](https://github.com/CoffeeBeforeArch/spinlocks)
- [My YouTube Channel: ](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account: ](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com

## Our Benchmark

We will evaluate our spinlock implementations using [Google Benchmark](https://github.com/google/benchmark). The structure of the benchmark can be found below:

```cpp
 // Small Benchmark
 static void bench(benchmark::State &s) {
   // Sweep over a range of threads
   auto num_threads = s.range(0);
 
   // Value we will increment
   std::int64_t val = 0;
 
   // Allocate a vector of threads
   std::vector<std::thread> threads;
   threads.reserve(num_threads);
 
   Spinlock sl;
 
   // Timing loop
   for (auto _ : s) {
     for (auto i = 0u; i < num_threads; i++) {
       threads.emplace_back([&] { inc(sl, val); });
     }
     // Join threads
     for (auto &thread : threads) thread.join();
     threads.clear();
   }
 }
 BENCHMARK(bench)
     ->RangeMultiplier(2)
     ->Range(1, std::thread::hardware_concurrency())
     ->UseRealTime()
     ->Unit(benchmark::kMillisecond);
```

We'll be evaluating our benchmark for a power-of-two number of threads (1, 2, 4, and 8 on my machine), where each thread runs a function called `inc`. This function can be found below:

```cpp
 // Increment val once each time the lock is acquired
 void inc(Spinlock &s, std::int64_t &val) {
   for (int i = 0; i < 100000; i++) {
     s.lock();
     val++;
     s.unlock();
   }
 }
```

For 100k iterations, our threads try and lock our spinlock, increment a shared value, then release the lock. This gives us a heavy contention scenario in which to test our spinlock.

## A Ticket Spinlock

Before we jump into our ticket spinlock implementation, we'll discuss why we should care about things like fairness and starvation.

### Fairness and Starvation

End-to-end performance and throughput are not the only metrics to consider when optimization. In many circumstances, we also care about things like fairness and starvation.

In the case of our spinlock, starvation occurs when one thread (or a subset of threads) hog access to our spinlock, starving other one or more other threads for access. So far, we have done nothing to prevent this from happening in any of our implementations (`naive`, `spin_locally`, `active_backoff`, `passive_backoff`, `exp_backoff`, `random_backoff`).

In fact, our exponential backoff implementation actualy increases how unfair our implementation is. To understand this, let's think about the core of the `lock` method from that implementation.

```cpp
   // Locking mechanism
   void lock() {
     // Start backoff at MIN_BACKOFF iterations
     int backoff_iters = MIN_BACKOFF;
   
     // Keep trying
     while (1) {
       // Try and grab the lock
       // Return if we get the lock
       if (!locked.exchange(true)) return;
   
       // If we didn't get the lock, just read the value which gets cached
       // locally. This leads to less traffic.
       // Pause for an exponentially increasing number of iterations
       do {
         // Pause for some number of iterations
         for (int i = 0; i < backoff_iters; i++) _mm_pause();
 
         // Get the backoff iterations for next time
         backoff_iters = std::min(backoff_iters << 1, MAX_BACKOFF);
   
         // Check to see if the lock is free
       } while (locked.load());
     }
   }
```

The longer a thread waits for a spinlock, the longer it waits in the `_mm_pause()` loop. That means that a thread that just started waiting for the lock will be checking the lock state faster, and be more likely to get the lock than a thread that has been waiting for the lock for a long time, and is checking the lock state very slowly.

In order to prevent starvation, and promote a fairness in how access to the lock is granted, we can use a ticket-based system for our lock

## The Ticket Spinlock Optimization

The core idea behind the ticket-spinlock is that the first thread to check if the spinlock is free should be the next thread to get the lock. What we're implementing is a FIFO (first in first out) lock.

Fundamentally, our spinlock will have 4 pieces:

## Low-Level Assembly

Let's take a look at how our low-level assembly for our benchmark looks with this new optimization:

```assembly
```

## Performance

Here are the end-to-end performance numbers for 1, 2, 4, and 8 threads:

## Final Thoughts

We've made a lot of progress in terms of performance and power consumption, but we have yet to discuss other important topics like fairness and starvation. We have no guarantee that some threads won't  be waiting for extreme amounts of time for the lock. We'll look at this in the next post with a ticket-based spinlock.

Thanks for reading,

--Nick

### Link to the source code

- [Source Code: ](https://github.com/CoffeeBeforeArch/spinlocks)
- [My YouTube Channel: ](https://www.youtube.com/channel/UCsi5-meDM5Q5NE93n_Ya7GA?view_as=subscriber)
- [My GitHub Account: ](https://github.com/CoffeeBeforeArch)
- My Email: CoffeeBeforeArch@gmail.com

