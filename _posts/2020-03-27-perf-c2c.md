---
layout: default
title: Detecting False Sharing with Perf C2C
---

# Detecting False Sharing with Perf C2C

In a [previous](https://coffeebeforearch.github.io/2019/12/28/false-sharing-tutorial.html) post we showed how false sharing cause serious slowdown in an application. However, we did not discuss how it can be debugged after-the-fact. While reasoning about your code can help you remove cases of false sharing ahead of time, there may be cases that are well-hidden in the code, or the result of runtime behavior of the application. For cases like this, tools can help. Perf C2C can be used for this exact purpose.

## Perf C2C

Perf C2C (Cache to Cache) is for analyzing shared data C2C/HITM. HITM stands for a load that hit in a modified cache line. The primary purpose of the tool is to report details on cache lines with the highest contention (e.g., the highest number of HITM accesses). More information can be found at the man page [here](http://man7.org/linux/man-pages/man1/perf-c2c.1.html).

## Example Code

To show off how to use Perf C2C, we'll use our sample code from last time. This includes a simple "work" function that increments an atomic integer, and a function that launches multiple threads, each of which calls the "work" function with a different atomic integer. The false sharing comes from the fact that all four of the atomic integers wind up on the same cache line. 


```cpp
void work(std::atomic<int>& a) {
  for(int i = 0; i < 100000; ++i) {
    a++;
  }
}

```

```cpp
void falseSharing() {
  // Create a single atomic integer
  std::atomic<int> a;
  a = 0;
  std::atomic<int> b;
  b = 0;
  std::atomic<int> c;
  c = 0;
  std::atomic<int> d;
  d = 0;

  // Four threads each with their own atomic<int>
  std::thread t1([&]() {work(a)});
  std::thread t2([&]() {work(b)});
  std::thread t3([&]() {work(c)});
  std::thread t4([&]() {work(d)});

  // Join the 4 threads
  t1.join();
  t2.join();
  t3.join();
  t4.join();
} 
```

This code was compiled using g++10 using the following command.

```bash
g++ false_sharing.cpp -lbenchmark -lpthread -O3 -march=native
```

![post compile](/assets/perf_c2c/post_compile.png)

The full source code can be found [here](https://github.com/CoffeeBeforeArch/uarch_benchmarks/tree/master/false_sharing).

## Using Perf C2C

Last time we showed that false sharing cause a ~3x slowdown compared to a serial implementation, with a ~40% miss-rate in the L1 cache. Let's see what information we can get with Perf C2C. Let's run the the application using the following:

```bash
perf c2c record ./false_sharing --benchmark_filter=falseSharing/real_time
```

![post run](/assets/perf_c2c/post_run.png)

Now we can load the data with perf. By default (on x86) we can the option of looking at samples for either load or store samples. 

```bash
perf report
```

![events](/assets/perf_c2c/events.png)

Let's look at the samples for loads. Unsurprisingly, we find that most of the samples are associated with the threads launched by our false-sharing benchmark. The long name associated with the symbol comes from the fact we are launching a new thread using a lambda.

![loads lambdas](/assets/perf_c2c/loads_lambdas.png)

We find that the loads and store samples are all associated with the atomic increment. Let's remember a few things from this slide. The first is where this atomic incremented is located in memory. We find the base of the lambda is at `0x407cd0`, and the incl is offset by `0x10`. We'll therefore focus on `0x407ce0` (the sum of the base address and the offset).

![lambda 4 hotspot](/assets/perf_c2c/lambda_4_hotspot.png)

Now let's exit out, and load in the data with c2c. We find a "Shared Data Cache Line Table" with a single entry (the cache line that holds all four of our atmoic integers). Notice all the high count of "Hitm". Again, these are cases where a thread misses in its L1 cache, and finds the line in a modified state in a different L1 cache.

```bash
perf c2c report
```

![perf c2c report](/assets/perf_c2c/perf_c2c_report.png)

We can get more information about a cache line by pressing `d` while it is selected in the table. When we do this, we find that cache line is being written contended at 4 places (our four threads running the "work" function). One thing to observe here is the code address. Notice how one of the entries is `0x407ce0`. This was the address of the incl instruction we looked at earlier! The other code addresses correspond to the incl instruction being executed on the other 3 threads.

![cacheline view](/assets/perf_c2c/cacheline_view.png)

## Compilation in Debug Mode

If you compiled your application with the `-g` flag (instead of `-O3`), you may see a different hotspot in your application. Now it looks like our hotspot is at `atomic_base.h`, a file that we did not write, or directly include.

![debug mode](/assets/perf_c2c/debug_mode.png)

However, if we look up what is actually at line 548 of `atomic_base.h`, we find that it is just the intrinsic for performing and atomic increment.

![fetch and add](/assets/perf_c2c/fetch_and_add.png)

In this, and many other scenarios, having a call graph can help you debug performance bug. If we take the same code, but record with the `-g` flag, we can trace back how we got to fetch\_and\_add. We can load in our data to perf the same way we did previously.

```bash
perf c2c record -g ./false_sharing --benchmark_filter=falseSharing/real_time
```

```bash
perf c2c report
```

![fetch and add](/assets/perf_c2c/call_graph.png)

Now we can see that our our atomic increment comes from `atomic_base.h`, which is called from the work function, which is running in our 4 threads launched with lambdas.

## Concluding remarks

This is by no means the only way to debug false sharing in an application. However, this should get you going in the right direction, and introduce you to some of the amazing tools out there for debugging performance bugs.

Thanks for reading,

--Nick

### Link to the source code

- [Source Code](https://github.com/CoffeeBeforeArch/spring_2020_tutorial/tree/master/false_sharing)

