---
layout: default
title: Detecting False Sharing with Perf C2C
---

# Detecting False Sharing with Perf C2C

In a [previous](https://coffeebeforearch.github.io/2019/12/28/false-sharing-tutorial.html) post we showed how false sharing cause serious slowdown in an application. However, we did not discuss how it can be debugged after-the-fact. While reasoning about your code can help you remove cases of false sharing ahead of time, there may be cases that are well-hidden in the code, or the result of runtime behavior of the application. For cases like this, tools can help. Perf C2C can be used for this exact purpose.

## Perf C2C

Perf C2C (Cache to Cache) is for analyzing shared data C2C/HITM. HITM stands for a load that hit in a modified cache line. The primary purpose of the tool is to report details on cache lines with the highest contention (e.g., the highest number of HITM accesses). More information can be found at the man page [here](http://man7.org/linux/man-pages/man1/perf-c2c.1.html).

## Example Code

To show off how to use Perf C2C, we'll use our sample code from last time. This includes a simple "work" function that increments an atomic integer, and a function that launches multiple threads, each of which calls the "work" function with a different atomic integer. The false sharing comes from the fact that all four of the atomic integers wind up on the same cache line. 


```cpp
void work(std::atomic<int>& a) {
  for(int i = 0; i < 100000; ++i) {
    a++;
  }
}

```

```cpp
void falseSharing() {
  // Create a single atomic integer
  std::atomic<int> a;
  a = 0;
  std::atomic<int> b;
  b = 0;
  std::atomic<int> c;
  c = 0;
  std::atomic<int> d;
  d = 0;

  // Four threads each with their own atomic<int>
  std::thread t1([&]() {work(a)});
  std::thread t2([&]() {work(b)});
  std::thread t3([&]() {work(c)});
  std::thread t4([&]() {work(d)});

  // Join the 4 threads
  t1.join();
  t2.join();
  t3.join();
  t4.join();
} 
```

This code was compiled using g++10 using the following command.

```bash
g++ false_sharing.cpp -lbenchmark -lpthread -O3 -march=native
```

The full source code can be found [here](https://github.com/CoffeeBeforeArch/uarch_benchmarks/tree/master/false_sharing).

## Using Perf C2C

Last time we showed that false sharing cause a ~3x slowdown compared to a serial implementation, with a ~40% miss-rate in the L1 cache. Let's see what information we can get with Perf C2C. Let's run the the application using the following:

```bash
perf c2c record ./false_sharing --benchmark_filter=falseSharing/real_time
```

We can the load in the data using the following:

```bash
perf c2c report
```

![post compile](/assets/perf_c2c/post_compile.png)
![post run](/assets/perf_c2c/post_run.png)
![events](/assets/perf_c2c/events.png)
![loads lambdas](/assets/perf_c2c/loads_lambdas.png)
![lambda 4 hotspot](/assets/perf_c2c/lambda_4_hotspot.png)
![perf c2c report](/assets/perf_c2c/perf_c2c_report.png)
![cacheline view](/assets/perf_c2c/cacheline_view.png)
![debug mode](/assets/perf_c2c/debug_mode.png)
![fetch and add](/assets/perf_c2c/fetch_and_add.png)


## Benchmarking and Profiling



## Concluding remarks

Thanks for reading,

--Nick

### Links to source and YouTube Tutorial

- [Source Code](https://github.com/CoffeeBeforeArch/uarch_benchmarks/tree/master/false_sharing)
- [YouTube Video](https://youtu.be/FygXDrRsaU8)

### Additional discussion points

- Our benchmarks could be rewritten using atomic references that have been introduced in C++20. These provide an excellent way to have selective atomicity.
- Real workloads typically do more that have 4 threads only compete for a single cache-line. However, there may be regions of execution where this pathological case exists, and still causes a significant performance impact.
- Why do you need to use an atomic integer at all? [Here's](https://stackoverflow.com/a/39396999/12482128) a Stack Overflow response answering that question.
